{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "376c23dc-7a32-4b27-ad49-2049192b03c4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Filter only Movies"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "airbnb_df = spark.table(\"az_adb_simbus_training.inside_air_bnb_project_schema.bronze_listings\")\n",
    "display(airbnb_df.limit(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44003583-204e-44b0-a22e-b976d0d3ce07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Basic Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57ddb708-da9a-4bba-baf7-0650ed348b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Removing Null Coulmns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d99b5690-af08-4d9b-8ae4-1efdcb2ff645",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "airbnb_df = airbnb_df.drop('neighbourhood_group', 'license')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6336a9d5-36f3-4494-befa-ef9b775577cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Checking remaining null count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25090e8c-ee1c-42e4-bcfa-32b662146cda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, when\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Calculate nulls for each column\n",
    "null_counts = airbnb_df.select([\n",
    "    _sum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in airbnb_df.columns\n",
    "]).collect()[0].asDict()\n",
    "\n",
    "# Convert to a DataFrame like pandas-style output\n",
    "null_df = spark.createDataFrame([Row(column=k, null_count=v) for k, v in null_counts.items()])\n",
    "null_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "885b1cf5-7feb-4396-af8b-f0f36da80ad8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pandas_df = airbnb_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "580aa7e2-3c27-4c24-a086-366362712d38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic nullity matrix\n",
    "msno.matrix(pandas_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46454d1f-e391-43f1-b6a2-d7b5985123c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "airbnb_df = airbnb_df.na.drop(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdde9e6e-0662-4895-83a1-43cc606102d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, when\n",
    "from pyspark.sql import Row\n",
    "\n",
    "null_counts = airbnb_df.select([\n",
    "    _sum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in airbnb_df.columns\n",
    "]).collect()[0].asDict()\n",
    "\n",
    "null_df = spark.createDataFrame([Row(column=k, null_count=v) for k, v in null_counts.items()])\n",
    "null_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92e49596-c974-4f27-9002-9915f9a61b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(airbnb_df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41bb810f-b743-4c80-868b-f3003a5bfc30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "desc_pdf = airbnb_df.describe().toPandas()\n",
    "\n",
    "# Transpose and set proper headers\n",
    "desc_pdf = desc_pdf.set_index('summary').T.reset_index().rename(columns={'index': 'column'})\n",
    "\n",
    "display(desc_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8bb6574-ad06-48f3-a7fa-e857b198ae51",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "cleaning the name column"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "whitelist_tokens = {\n",
    "    \"p/\", \"p/mo\", \"p/month\", \"p/wk\", \"p/week\", \"p/day\", \"p/sq ft\",\n",
    "    \"sq ft\", \"sq. ft.\", \"sq m\", \"br\", \"ba\", \"w/d\", \"a/c\", \"hwd\", \"apt\",\n",
    "    \"unit\", \"ft\", \"hr\", \"mo\", \"rm\", \"dep\", \"incl\", \"util\", \"pkg\", \"ref\",\n",
    "    \"elec\", \"gas\", \"hwh\"\n",
    "}\n",
    "\n",
    "non_alphanum_pattern = re.compile(r\"[^a-zA-Z0-9/]\")\n",
    "\n",
    "def strict_clean_text(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "\n",
    "    text = re.sub(r\"<.*?>\", \" \", text) #html tags\n",
    "\n",
    "    tokens = text.split()\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        token_lower = token.lower()\n",
    "        if token_lower in whitelist_tokens:\n",
    "            cleaned_tokens.append(token)\n",
    "        else:\n",
    "            cleaned = re.sub(non_alphanum_pattern, \" \", token)\n",
    "            if cleaned:\n",
    "                cleaned_tokens.append(cleaned)\n",
    "\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "strict_clean_text_udf = udf(strict_clean_text, StringType())\n",
    "airbnb_df = airbnb_df.withColumn(\"name_cleaned\", strict_clean_text_udf(col(\"name\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d37269d7-55e5-4910-8f45-98d0007635ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(airbnb_df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad6dd78f-8c9a-4b04-9eea-b61ff93a87e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql import Row\n",
    "\n",
    "unique_counts_row = airbnb_df.agg(*[\n",
    "    countDistinct(col_name).alias(col_name) for col_name in airbnb_df.columns\n",
    "]).collect()[0]\n",
    "\n",
    "unique_counts_list = [\n",
    "    Row(column=col_name, unique_count=unique_counts_row[col_name])\n",
    "    for col_name in airbnb_df.columns\n",
    "]\n",
    "\n",
    "unique_counts_df = spark.createDataFrame(unique_counts_list)\n",
    "unique_counts_df.orderBy(\"unique_count\", ascending=False).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35ca2e45-3e85-47a8-801a-98ebf4df79fe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "last_review to proper Datatime format"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "airbnb_df = airbnb_df.withColumn(\"last_review\", to_date(\"last_review\", \"yyyy-MM-dd\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4dc07d6-9c64-40f8-8daa-56f26be544c0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "save as Silver Table"
    }
   },
   "outputs": [],
   "source": [
    "final_df_with_names.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"az_adb_simbus_training.inside_air_bnb_project_schema.silver_listing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60c43176-2921-45f2-b3b4-218f1e68b69a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    ". Monthly Price Aggregates\n",
    "Columns:\n",
    "- listing_id\n",
    "- neighborhood\n",
    "- year\n",
    "- month\n",
    "- avg_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86392ce4-3a8a-4714-8a2e-df99cf1dd8d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Monthly Occupancy Rates\n",
    "Columns:\n",
    "- listing_id\n",
    "- neighborhood\n",
    "- year\n",
    "- month\n",
    "- occupancy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d64aa9a-d69a-4f5c-b943-98848e8ab3f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Average Rating per Listing\n",
    "Columns:\n",
    "- listing_id\n",
    "- avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb6cd0a7-b5cc-4688-af24-50f845be26a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "4. Host Features\n",
    "Columns:\n",
    "- host_id\n",
    "- is_superhost\n",
    "- response_time\n",
    "- total_listings\n",
    "- avg_rating (from reviews)\n",
    "- avg_price (from listings)\n",
    "- commidites offer(hard to do)/text extraction"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8182667184451399,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_layer",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
